{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymystem3\n",
    "import pymorphy2\n",
    "import numpy as np\n",
    "import opencorpora\n",
    "\n",
    "from collections import defaultdict\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from operator import itemgetter, attrgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opencorpora corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = opencorpora.load('../annot.opcorpora.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def parse(sentence):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MystemAnalyzer(Analyzer):\n",
    "    POS = {\n",
    "        'A': ['ADJF', 'ADJS'],\n",
    "        'ADV': ['ADVB'],\n",
    "        'ADVPRO': ['ADVB'],\n",
    "        'ANUM': ['ADJF', 'ADJS'],\n",
    "        'APRO': ['ADJF', 'ADJS'],\n",
    "        'COM': [],\n",
    "        'CONJ': ['CONJ'],\n",
    "        'INTJ': ['INTJ'],\n",
    "        'NUM': ['NUMR'],\n",
    "        'PART': ['PRCL'],\n",
    "        'PR': ['PREP'],\n",
    "        'S': ['NOUN'],\n",
    "        'SPRO': ['NPRO'],\n",
    "        'V': ['VERB', 'INFN']\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._analyzer = pymystem3.Mystem()\n",
    "        self._re_pos = re.compile('[a-zA-Z_]*')\n",
    "    \n",
    "    @staticmethod\n",
    "    def _not_empty(words):\n",
    "        return list(filter(lambda it: 'analysis' in it, words))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_parse(words):\n",
    "        return zip(map(itemgetter('text'), words), \n",
    "                   map(lambda it: it['analysis'][0] if it['analysis'] else None, words))\n",
    "            \n",
    "    def _get_pos(self, parse):\n",
    "        return self.POS[self._re_pos.match(parse['gr']).group(0)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_lexema(parse):\n",
    "        return parse['lex']\n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        parses = []\n",
    "\n",
    "        for text, parse in self._get_parse(self._not_empty(self._analyzer.analyze(sentence))):\n",
    "            parses.append((self._get_lexema(parse) if parse else text, self._get_pos(parse) if parse else []))\n",
    "            \n",
    "        return parses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphAnalyzer(Analyzer):\n",
    "    def __init__(self):\n",
    "        self._analyzer = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _not_empty(words):\n",
    "        return filter(lambda it: 'analysis' in it, words)\n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        parses = []\n",
    "        \n",
    "        for parse in map(lambda it: self._analyzer.parse(it)[0], sentence.split()):\n",
    "            parses.append((parse.normal_form, [parse.tag.POS]))\n",
    "            \n",
    "        return parses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    tokens = list(filter(lambda it: 'PNCT' not in it.parse.grammemes, sentence.tokens))\n",
    "    words = list(map(attrgetter('source'), tokens))\n",
    "    parses = list(map(lambda it: (it.parse.lemma, it.parse.grammemes[0]), tokens))\n",
    "    return words, parses\n",
    "\n",
    "def sentences(docs):\n",
    "    for doc in docs:\n",
    "        for sentence in doc.sentences:\n",
    "            yield sentence\n",
    "\n",
    "def evaluate(docs, analyzers):\n",
    "    words_count = 0\n",
    "    lemma_precision = defaultdict(int) \n",
    "    pos_precision = defaultdict(int)\n",
    "    \n",
    "    for sentence in sentences(docs):\n",
    "        words, parses = process_sentence(sentence)\n",
    "        sentence_clear = ' '.join(words).lower()\n",
    "        \n",
    "        words_count += len(parses)\n",
    "        \n",
    "        for analyzer in analyzers:\n",
    "            \n",
    "            for parse_true, parse_pred in zip(parses, analyzer.parse(sentence_clear)):\n",
    "                if parse_true[0] == parse_pred[0]:\n",
    "                    lemma_precision[analyzer.__class__.__name__] += 1\n",
    "                \n",
    "                if parse_true[1] in parse_pred[1]:\n",
    "                    pos_precision[analyzer.__class__.__name__] += 1\n",
    "                    \n",
    "    for key in lemma_precision:\n",
    "        lemma_precision[key] /= words_count\n",
    "        \n",
    "    for key in pos_precision:\n",
    "        pos_precision[key] /= words_count\n",
    "    \n",
    "    return lemma_precision, pos_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = np.random.choice(corpus.docs, size=200, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzers = [MystemAnalyzer(), MorphAnalyzer()]\n",
    "lemma_precision, pos_precision = evaluate(docs, analyzers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma precision:\n",
      "MystemAnalyzer: 63.2%\n",
      "MorphAnalyzer: 81.5%\n"
     ]
    }
   ],
   "source": [
    "print('Lemma precision:')\n",
    "for analyzer in analyzers:\n",
    "    name = analyzer.__class__.__name__\n",
    "    print('{}: {:0.1f}%'.format(name, 100 * lemma_precision[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS precision:\n",
      "MystemAnalyzer: 72.3%\n",
      "MorphAnalyzer: 87.3%\n"
     ]
    }
   ],
   "source": [
    "print('POS precision:')\n",
    "for analyzer in analyzers:\n",
    "    name = analyzer.__class__.__name__\n",
    "    print('{}: {:0.1f}%'.format(name, 100 * pos_precision[name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
